"""
ACE + ReAct Agent - ä½¿ç”¨ ACE èŒƒå¼æå‡ ReAct Agent çš„æ€§èƒ½ï¼ˆç®€åŒ–ç‰ˆï¼‰

ä½¿ç”¨ç®€åŒ–çš„ ReAct Agentï¼ˆåŸºäº LangGraph å†…ç½®ç»„ä»¶ï¼‰ä¸ ACE æ¡†æ¶æ•´åˆã€‚

æ ¸å¿ƒæ€è·¯ï¼š
1. ReAct Agent ä½œä¸º Generatorï¼ˆä½¿ç”¨ ToolNode å’Œ tools_conditionï¼‰
2. Evaluator è¯„ä¼° Agent çš„ç­”æ¡ˆæ˜¯å¦æ­£ç¡®
3. Reflector åˆ†æ Agent çš„æ¨ç†è¿‡ç¨‹
4. Curator å°†æ¨¡å¼å­˜å‚¨ä¸ºç­–ç•¥ï¼Œä¾›åç»­ä½¿ç”¨
"""

from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.tools import tool
import sys
from pathlib import Path



# ç»Ÿä¸€ä½¿ç”¨ ace_langgraph å‰ç¼€å¯¼å…¥
from  playbook import Playbook
from  react_agent import ReActAgent, get_default_tools
from  reflector import Reflector
from  curator import Curator
from  evaluator import Evaluator
from  agent_types import (
    ReactQuestion, ReactAgentResult, EvaluatorResult,
    ReflectionResult, CuratorResult
)
    
from typing_extensions import TypedDict


class ACEReActState(TypedDict):
    """ACE + ReAct å·¥ä½œæµçŠ¶æ€ã€‚
    
    æ‰€æœ‰æ•°æ®éƒ½ä»¥ç±»å‹å¯¹è±¡å½¢å¼å­˜å‚¨ï¼Œé¿å…å†—ä½™å­—æ®µã€‚
    éœ€è¦çš„ä¿¡æ¯éƒ½å¯ä»¥ä»å„ä¸ª Result å¯¹è±¡ä¸­è·å–ã€‚
    """
    # è¾“å…¥å¯¹è±¡
    react_question: ReactQuestion
    
    # å„ç»„ä»¶è¾“å‡ºå¯¹è±¡
    react_result: ReactAgentResult
    evaluation: EvaluatorResult
    reflection: ReflectionResult
    curator_result: CuratorResult  # æ–°å¢ï¼šä¿å­˜ curator ç»“æœ

class ACEReActWorkflow:
    """
    ACE + ReAct å·¥ä½œæµï¼ˆç®€åŒ–ç‰ˆï¼‰ã€‚
    
    å°†ç®€åŒ–çš„ ReAct Agent é›†æˆåˆ° ACE æ¡†æ¶ä¸­ã€‚
    è‡ªåŠ¨ç®¡ç† Playbook æŒä¹…åŒ–ï¼ˆåŠ è½½/ä¿å­˜ï¼‰ã€‚
    """
    
    # é»˜è®¤çš„ Playbook æ–‡ä»¶è·¯å¾„
    DEFAULT_PLAYBOOK_PATH = "ace_react_playbook.json"
    
    def __init__(
        self,
        tools: List = None,
        model_name: str = "qwen-plus",
        max_iterations: int = 50, #æš‚æ—¶æ²¡ç”¨
        use_vector_retrieval: bool = True,
        playbook_path: str = None,
        auto_save: bool = True
    ):
        """
        åˆå§‹åŒ– ACE + ReAct å·¥ä½œæµã€‚
        
        å‚æ•°ï¼š
            tools: ReAct Agent å¯ç”¨çš„å·¥å…·åˆ—è¡¨
            model_name: LLM æ¨¡å‹åç§°
            max_iterations: Agent æœ€å¤§è¿­ä»£æ¬¡æ•°
            use_vector_retrieval: æ˜¯å¦ä½¿ç”¨å‘é‡æ£€ç´¢ï¼ˆæ¨èï¼‰
            playbook_path: Playbook æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šace_react_playbook.jsonï¼‰
                          è®¾ç½®ä¸º None å¯åˆ›å»ºä¸ä¿å­˜çš„ä¸´æ—¶ Playbook
            auto_save: æ˜¯å¦åœ¨æ¯æ¬¡è¿è¡Œåè‡ªåŠ¨ä¿å­˜ Playbook
        """
        self.tools = tools or get_default_tools()
        self.model_name = model_name
        self.max_iterations = max_iterations
        self.use_vector_retrieval = use_vector_retrieval
        self.playbook_path = playbook_path if playbook_path is not None else self.DEFAULT_PLAYBOOK_PATH
        self.auto_save = auto_save
        
        # è‡ªåŠ¨åŠ è½½æˆ–åˆ›å»º Playbook
        self.playbook = self._load_or_create_playbook()
        
        # åˆ›å»º ReAct Agentï¼ˆä¼šå¼•ç”¨ self.playbookï¼Œèƒ½è·å–æœ€æ–°ç­–ç•¥ï¼‰
        self.agent = ReActAgent(
            playbook=self.playbook,  # ä¼ é€’å¼•ç”¨ï¼Œagent ä¼šè®¿é—®æœ€æ–°çš„ playbook
            tools=self.tools,
            model_name=self.model_name,
            max_iterations=self.max_iterations,
            verbose=False,
            top_k_strategies=5
        )

        self.evaluator = Evaluator(model_name=model_name)
        self.reflector = Reflector(playbook=self.playbook, model_name=model_name)
        self.curator = Curator(playbook=self.playbook, model_name=model_name)
        
        # æ„å»ºå·¥ä½œæµå›¾ï¼ˆä½¿ç”¨æ¡ä»¶è¾¹ï¼‰
        self.graph = self._build_graph()
    
    def _load_or_create_playbook(self) -> Playbook:
        """
        åŠ è½½æˆ–åˆ›å»º Playbookã€‚
        
        è¿”å›ï¼š
            Playbook å®ä¾‹
        """
        from pathlib import Path
        
        # å¦‚æœæŒ‡å®šäº†è·¯å¾„ä¸”æ–‡ä»¶å­˜åœ¨ï¼Œå°è¯•åŠ è½½
        if self.playbook_path and Path(self.playbook_path).exists():
            try:
                print(f"ğŸ“‚ ä» {self.playbook_path} åŠ è½½å·²æœ‰çš„ Playbook...")
                playbook = Playbook.load_from_file(self.playbook_path,enable_retrieval=self.use_vector_retrieval)
                stats = playbook.stats()
                print(f"   âœ“ æˆåŠŸåŠ è½½ {stats['total_strategies']} ä¸ªç­–ç•¥")
                return playbook
            except Exception as e:
                print(f"   âš ï¸  åŠ è½½å¤±è´¥: {e}")
                print(f"   åˆ›å»ºæ–°çš„ Playbook")
        elif self.playbook_path:
            print(f"ğŸ“ æœªæ‰¾åˆ° {self.playbook_path}ï¼Œåˆ›å»ºæ–°çš„ Playbook")
        else:
            print(f"ğŸ“ åˆ›å»ºä¸´æ—¶ Playbookï¼ˆä¸ä¼šä¿å­˜åˆ°æ–‡ä»¶ï¼‰")
        
        # åˆ›å»ºæ–° Playbookï¼ˆæ ¹æ®é…ç½®é€‰æ‹©ç±»å‹ï¼‰
        return Playbook(
            enable_retrieval=self.use_vector_retrieval
        )
    
    def _save_playbook(self):
        """
        ä¿å­˜ Playbook åˆ°æ–‡ä»¶ã€‚
        """
        if not self.playbook_path:
            # æ²¡æœ‰æŒ‡å®šè·¯å¾„ï¼Œä¸ä¿å­˜ï¼ˆä¸´æ—¶ Playbookï¼‰
            return
            
        try:
            self.playbook.save_to_file(self.playbook_path)
            print(f"ğŸ’¾ å·²è‡ªåŠ¨ä¿å­˜ Playbook åˆ° {self.playbook_path}")
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜ Playbook å¤±è´¥: {e}")
    
    def _should_evaluate(self, state: ACEReActState) -> str:
        """
        æ¡ä»¶å‡½æ•°ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦è¯„ä¼°ã€‚
        
        æ ¹æ® ground_truth æ˜¯å¦å­˜åœ¨å†³å®šè·¯ç”±ï¼š
        - æœ‰ ground_truth â†’ "evaluate" (è®­ç»ƒæ¨¡å¼)
        - æ—  ground_truth â†’ "skip_evaluate" (ç”Ÿäº§æ¨¡å¼)
        """
        react_question = state.get("react_question")
        has_ground_truth = react_question and react_question.ground_truth
        return "evaluate" if has_ground_truth else "skip_evaluate"
    
    def _build_graph(self) -> StateGraph:
        """
        æ„å»º LangGraph å·¥ä½œæµï¼ˆä½¿ç”¨æ¡ä»¶è¾¹ï¼‰ã€‚
        
        å·¥ä½œæµç»“æ„ï¼š
        - react_agent â†’ æ¡ä»¶åˆ¤æ–­
          - æœ‰ ground_truth â†’ evaluator â†’ reflector â†’ curator
          - æ—  ground_truth â†’ reflector â†’ curator
        """
        workflow = StateGraph(ACEReActState)
        
        # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
        workflow.add_node("react_agent", self._react_agent_node)
        workflow.add_node("evaluator", self._evaluator_node)
        workflow.add_node("reflector", self._reflector_node)
        workflow.add_node("curator", self._curator_node)
        
        # è®¾ç½®å…¥å£
        workflow.set_entry_point("react_agent")
        
        # ä½¿ç”¨æ¡ä»¶è¾¹ï¼šreact_agent åæ ¹æ®æ˜¯å¦æœ‰ ground_truth å†³å®šè·¯ç”±
        workflow.add_conditional_edges(
            "react_agent",
            lambda state: "evaluator" if state["react_question"].ground_truth else "reflector",
            {"evaluator": "evaluator", "reflector": "reflector"}
        )
        
        # evaluator åç»­è·¯å¾„
        workflow.add_edge("evaluator", "reflector")
        
        # reflector å’Œ curator çš„è·¯å¾„
        workflow.add_edge("reflector", "curator")
        workflow.add_edge("curator", END)
        
        return workflow.compile()
    
    def _react_agent_node(self, state: ACEReActState) -> ACEReActState:
        """
        ReAct Agent èŠ‚ç‚¹ - ä½œä¸º Generatorã€‚
        
        ä½¿ç”¨åˆå§‹åŒ–æ—¶åˆ›å»ºçš„ Agent å®ä¾‹ã€‚
        Agent å†…éƒ¨ä¼šåŠ¨æ€è·å–æœ€æ–°çš„ playbook ç­–ç•¥ï¼ˆé€šè¿‡å¼•ç”¨ï¼‰ã€‚
        """
        # ç›´æ¥ä½¿ç”¨ state ä¸­çš„ ReactQuestion å¯¹è±¡
        react_question = state["react_question"]
        
        # è°ƒç”¨ agentï¼Œç›´æ¥è¿”å› ReactAgentResult å¯¹è±¡
        react_result = self.agent.run(react_question)
        
        # ä¿å­˜ ReactAgentResult å¯¹è±¡åˆ° state
        state["react_result"] = react_result
        
        return state
    
    def _evaluator_node(self, state: ACEReActState) -> ACEReActState:
        """è¯„ä¼°å™¨èŠ‚ç‚¹ - ä½¿ç”¨ LLM æ£€æŸ¥ç­”æ¡ˆæ­£ç¡®æ€§ã€‚"""
        # ç›´æ¥ä½¿ç”¨ state ä¸­çš„ç±»å‹å¯¹è±¡
        react_question = state["react_question"]
        react_result = state["react_result"]
        
        # è°ƒç”¨æ–°æ¥å£
        evaluation = self.evaluator.evaluate(react_question, react_result)
        state["evaluation"] = evaluation
        return state
    
    def _reflector_node(self, state: ACEReActState) -> ACEReActState:
        """
        åæ€å™¨èŠ‚ç‚¹ - åˆ†ææ¨ç†è¿‡ç¨‹ã€‚
        
        ä½¿ç”¨ Reflector æ¨¡å—åˆ†æå®Œæ•´çš„æ¶ˆæ¯å†å²ï¼Œæ‰¾å‡ºæˆåŠŸ/å¤±è´¥æ¨¡å¼ã€‚
        æ”¯æŒè®­ç»ƒæ¨¡å¼ï¼ˆæœ‰è¯„ä¼°ç»“æœï¼‰å’Œç”Ÿäº§æ¨¡å¼ï¼ˆæ— è¯„ä¼°ç»“æœï¼‰ã€‚
        """
        # ç›´æ¥ä½¿ç”¨ state ä¸­çš„ç±»å‹å¯¹è±¡
        react_question = state["react_question"]
        react_result = state["react_result"]
        evaluator_result = state.get("evaluation")
        
        # è°ƒç”¨æ–°æ¥å£
        reflection_result = self.reflector.reflect(
            react_question,
            react_result,
            evaluator_result
        )
        
        # åªä¿å­˜ç»“æœå¯¹è±¡
        state["reflection"] = reflection_result
        
        return state
    
    def _curator_node(self, state: ACEReActState) -> ACEReActState:
        """
        ç­–å±•å™¨èŠ‚ç‚¹ - æå–æ–°ç­–ç•¥ã€‚
        
        ä½¿ç”¨ Curator æ¨¡å—ä»åæ€ä¸­æå–å¯å¤ç”¨çš„ç­–ç•¥æ¨¡å¼ã€‚
        æ”¯æŒè®­ç»ƒæ¨¡å¼ï¼ˆæœ‰è¯„ä¼°ç»“æœï¼‰å’Œç”Ÿäº§æ¨¡å¼ï¼ˆæ— è¯„ä¼°ç»“æœï¼‰ã€‚
        """
        # ç›´æ¥ä½¿ç”¨ state ä¸­çš„ç±»å‹å¯¹è±¡
        react_question = state["react_question"]
        react_result = state["react_result"]
        evaluator_result = state.get("evaluation")
        reflection_result = state["reflection"]
        
        # è°ƒç”¨æ–°æ¥å£ï¼ˆplaybook å·²åœ¨ curator åˆå§‹åŒ–æ—¶ä¼ å…¥ï¼‰
        curation_result = self.curator.curate(
            react_question,
            react_result,
            evaluator_result,
            reflection_result
        )
        
        # åªä¿å­˜ç»“æœå¯¹è±¡
        state["curator_result"] = curation_result
        
        return state
    
    def run(
        self,
        question: ReactQuestion,
        verbose: bool = True
    ) -> Dict[str, Any]:
        """
        è¿è¡Œ ACE + ReAct å·¥ä½œæµã€‚
        
        æ ¹æ®æ˜¯å¦æä¾› ground_truth è‡ªåŠ¨é€‰æ‹©è®­ç»ƒæ¨¡å¼æˆ–ç”Ÿäº§æ¨¡å¼ï¼š
        - è®­ç»ƒæ¨¡å¼ï¼ˆæœ‰ ground_truthï¼‰ï¼šåŒ…å«è¯„ä¼°èŠ‚ç‚¹
        - ç”Ÿäº§æ¨¡å¼ï¼ˆæ—  ground_truthï¼‰ï¼šè·³è¿‡è¯„ä¼°èŠ‚ç‚¹
        
        ä½¿ç”¨æ¡ä»¶è¾¹è‡ªåŠ¨è·¯ç”±ï¼Œæ— éœ€æ‰‹åŠ¨åˆ¤æ–­ã€‚
        
        å‚æ•°ï¼š
            question: ReactQuestion å¯¹è±¡
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            
        è¿”å›ï¼šåŒ…å«ç­”æ¡ˆã€è¯„ä¼°ã€åæ€ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        # åˆå§‹åŒ–çŠ¶æ€ï¼ˆæ‰€æœ‰å­—æ®µéƒ½æ˜¯ç±»å‹å¯¹è±¡ï¼‰
        initial_state: ACEReActState = {
            "react_question": question,
            "react_result": None,
            "evaluation": None,
            "reflection": None,
            "curator_result": None
        }
        
        if verbose:
            has_ground_truth = question.ground_truth is not None
            mode = "è®­ç»ƒæ¨¡å¼" if has_ground_truth else "ç”Ÿäº§æ¨¡å¼"
            print(f"\n{'='*60}")
            print(f"é—®é¢˜ï¼š{question.question}")
            print(f"æ¨¡å¼ï¼š{mode}")
            print(f"{'='*60}\n")
        
        # æ‰§è¡Œå·¥ä½œæµï¼ˆæ¡ä»¶è¾¹ä¼šè‡ªåŠ¨å¤„ç†è·¯ç”±ï¼‰
        result = self.graph.invoke(initial_state)
        
        # è‡ªåŠ¨ä¿å­˜ Playbookï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.auto_save:
            self._save_playbook()
        
        if verbose:
            print("\n" + "="*60)
            print("æ‰§è¡Œç»“æœ")
            print("="*60)
            
            # æ˜¾ç¤º ReAct Agent ç»“æœ
            react_result = result.get("react_result")
            if react_result:
                print("\nã€ReAct Agentã€‘")
                print(react_result.as_str())
            
            # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
            evaluation = result.get("evaluation")
            if evaluation:
                print("\nã€è¯„ä¼°ç»“æœã€‘")
                print(evaluation.as_str())
            else:
                print("\nã€è¯„ä¼°ç»“æœã€‘")
                print("(ç”Ÿäº§æ¨¡å¼ï¼Œæœªè¯„ä¼°)")
            
            # æ˜¾ç¤ºåæ€ç»“æœ
            reflection_result = result.get('reflection')
            if reflection_result:
                print("\nã€åæ€ç»“æœã€‘")
                print(reflection_result.as_str())
            else:
                print("\nã€åæ€ç»“æœã€‘")
                print("(æœªç”Ÿæˆ)")
            
            # æ˜¾ç¤ºç­–å±•ç»“æœ
            curator_result = result.get('curator_result')
            if curator_result:
                print("\nã€ç­–å±•ç»“æœã€‘")
                print(curator_result.as_str())
            else:
                print("\nã€ç­–å±•ç»“æœã€‘")
                print("(æœªç”Ÿæˆ)")
            
            print(f"\nã€Playbookã€‘")
            print(f"æ€»ç­–ç•¥æ•°ï¼š{len(self.playbook)}")
            print()
        
        return result
    
    def ask(
        self,
        question: ReactQuestion,
        verbose: bool = True
    ) -> ReactAgentResult:
        """
        å¿«é€Ÿè¯¢é—®æ¨¡å¼ - ä»…æ‰§è¡Œ ReAct Agentï¼Œä¸è¿›è¡Œè¯„ä¼°ã€åæ€å’Œå­¦ä¹ ã€‚
        
        é€‚ç”¨åœºæ™¯ï¼š
        - å¿«é€Ÿè·å–ç­”æ¡ˆï¼Œä¸éœ€è¦å­¦ä¹ 
        - ç”Ÿäº§ç¯å¢ƒç›´æ¥ä½¿ç”¨
        - æµ‹è¯• Agent æ€§èƒ½
        
        å‚æ•°ï¼š
            question: ReactQuestion å¯¹è±¡ï¼ˆå¯ä»¥ä¸æä¾› ground_truthï¼‰
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            
        è¿”å›ï¼šReactAgentResult å¯¹è±¡
        
        ç¤ºä¾‹ï¼š
            >>> workflow = ACEReActWorkflow()
            >>> result = workflow.ask(ReactQuestion("2+2ç­‰äºå¤šå°‘ï¼Ÿ"))
            >>> print(result.answer)
        """
        if verbose:
            print(f"\n{'='*60}")
            print(f"å¿«é€Ÿè¯¢é—®æ¨¡å¼")
            print(f"é—®é¢˜ï¼š{question.question}")
            print(f"{'='*60}\n")
        
        # åªæ‰§è¡Œ react_agent èŠ‚ç‚¹
        initial_state: ACEReActState = {
            "react_question": question,
            "react_result": None,
            "evaluation": None,
            "reflection": None,
            "curator_result": None
        }
        
        # ç›´æ¥è°ƒç”¨ react_agent èŠ‚ç‚¹
        state = self._react_agent_node(initial_state)
        react_result = state["react_result"]
        
        if verbose:
            print("\n" + "="*60)
            print("æ‰§è¡Œç»“æœ")
            print("="*60)
            
            if react_result:
                print("\nã€ReAct Agentã€‘")
                print(react_result.as_str())
            
            print()
        
        return react_result

# ========== ä¸»å‡½æ•°æµ‹è¯• ==========

def main():
    """æµ‹è¯• ACE + ReAct å·¥ä½œæµã€‚"""
    import os
    
    # æ£€æŸ¥ API key
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    print("\n" + "="*60)
    print("ACE + ReAct Agent æµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰")
    print("="*60)
    
    # 1. åˆ›å»ºå·¥ä½œæµ
    workflow = ACEReActWorkflow(
        tools=get_default_tools(),
        model_name="gpt-4o-mini",
        max_iterations=10,
        use_vector_retrieval=True
    )

    # 2. è®­ç»ƒé—®é¢˜
    questions = [
        ReactQuestion(
            question="è®¡ç®— (25 + 17) * 3 - 8 çš„ç»“æœï¼Œå¹¶éªŒè¯ç­”æ¡ˆæ˜¯å¦ä¸ºå¶æ•°",
            ground_truth="118ï¼Œæ˜¯å¶æ•°",
            context=""
        ),
        ReactQuestion(
            question="æœç´¢ Python è¯­è¨€çš„åˆ›å»ºè€…ï¼Œå¹¶è¯´æ˜ä»–åˆ›å»º Python çš„å¹´ä»½",
            ground_truth="Guido van Rossumï¼Œ1991å¹´",
            context=""
        ),
        ReactQuestion(
            question="æœç´¢ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°åç§°å’Œæµ·æ‹”é«˜åº¦ï¼Œç„¶åè®¡ç®—å¦‚æœä¸€ä¸ªäººæ¯å¤©çˆ¬å‡500ç±³ï¼Œéœ€è¦å¤šå°‘å¤©æ‰èƒ½åˆ°è¾¾é¡¶å³°",
            ground_truth="ç ç©†æœ—ç›å³°ï¼Œ8849ç±³ï¼Œéœ€è¦çº¦18å¤©",
            context=""
        ),
    ]
    
    # 3. è¿è¡Œè®­ç»ƒ
    print("\nå¼€å§‹è®­ç»ƒé˜¶æ®µ...\n")

    for i, question in enumerate(questions, 1):
        print(f"\n{'='*60}")
        print(f"é—®é¢˜ {i}/{len(questions)}")
        print(f"{'='*60}")
        workflow.run(question, verbose=True)
    
    # 4. æŸ¥çœ‹å­¦åˆ°çš„ç­–ç•¥
    print("\n" + "="*60)
    print("å­¦ä¹ æˆæœ")
    print("="*60)
    
    stats = workflow.playbook.stats()
    print(f"\nç­–ç•¥æ€»æ•°ï¼š{stats['total_strategies']}")
    print(f"åˆ†ç±»æ•°ï¼š{stats['categories']}")
    print(f"æ ‡è®°ç»Ÿè®¡ï¼šâœ“{stats['tags']['helpful']} / âœ—{stats['tags']['harmful']} / ~{stats['tags']['neutral']}")
    print(f"å¹³å‡å¾—åˆ†ï¼š{stats['avg_score']:.2f}")
    
    if len(workflow.playbook) > 0:
        print("\nå‰ 5 ä¸ªç­–ç•¥ï¼ˆæŒ‰åˆ†æ•°æ’åºï¼‰ï¼š")
        top_strategies = workflow.playbook.get_top_strategies(n=5)
        
        for i, strategy in enumerate(top_strategies, 1):
            print(f"\n{i}. [{strategy.id}] (åˆ†æ•°: {strategy.score})")
            print(f"   {strategy.content}")
            print(f"   âœ“{strategy.helpful_count} / âœ—{strategy.harmful_count} / ~{strategy.neutral_count}")
            print(f"   åˆ›å»ºäº: {strategy.created_at[:10]}")
        
    # 5. æµ‹è¯•åº”ç”¨ï¼ˆå¤æ‚é—®é¢˜ - ç»¼åˆè¿ç”¨è®­ç»ƒçš„èƒ½åŠ›ï¼‰
    print("\n" + "="*60)
    print("æµ‹è¯•é˜¶æ®µ - å¤æ‚é—®é¢˜æµ‹è¯•")
    print("="*60 + "\n")
    
    test_question = ReactQuestion(
        question="æœç´¢ä¸–ç•Œä¸Šæœ€æ·±çš„æµ·æ²Ÿåç§°å’Œæ·±åº¦ï¼Œç„¶åè®¡ç®—å¦‚æœä¸€ä¸ªæ½œæ°´å™¨æ¯å°æ—¶ä¸‹æ½œ1000ç±³ï¼Œéœ€è¦å¤šå°‘å°æ—¶æ‰èƒ½åˆ°è¾¾æµ·æ²Ÿæœ€æ·±å¤„ã€‚æœ€åéªŒè¯è®¡ç®—ç»“æœæ˜¯å¦ä¸ºæ•´æ•°å°æ—¶æ•°ã€‚",
        context=""
    )
    print(f"é—®é¢˜ï¼š{test_question.question}")
    print("æ¨¡å¼ï¼šç»¼åˆæµ‹è¯•ï¼ˆæœç´¢ + è®¡ç®— + éªŒè¯ï¼‰\n")
    
    result = workflow.run(test_question, verbose=True)
    
    print("\nğŸ’¡ æ­¤é—®é¢˜æµ‹è¯•äº†è®­ç»ƒä¸­å­¦åˆ°çš„å¤šä¸ªèƒ½åŠ›ï¼š")
    print("   âœ“ ä¿¡æ¯æœç´¢èƒ½åŠ›")
    print("   âœ“ å¤šæ­¥è®¡ç®—èƒ½åŠ›")
    print("   âœ“ æ•°å€¼éªŒè¯èƒ½åŠ›")
    # ä» curator_result è·å–æ–°ç­–ç•¥æ•°é‡
    curator_result = result.get('curator_result')
    new_strategies_count = curator_result.added_count if curator_result else 0
    print(f"   ğŸ“š æœ¬æ¬¡æ–°å¢ {new_strategies_count} ä¸ªç­–ç•¥")
    

if __name__ == "__main__":
    import sys
    main()
